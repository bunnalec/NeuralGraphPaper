{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alec\\AppData\\Local\\Temp\\ipykernel_11896\\1838974486.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from NeuralGraph import NeuralGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f35018f950>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x, y, valid_split=.2, test_split=.2):\n",
    "    classes = np.unique(y)\n",
    "    train_valid_split = round(len(classes)*(1-(valid_split+test_split)))\n",
    "    valid_test_split = round(len(classes)*(1-test_split))\n",
    "\n",
    "    train_classes = set(classes[:train_valid_split])\n",
    "    valid_classes = set(classes[train_valid_split:valid_test_split])\n",
    "    test_classes = set(classes[valid_test_split:])\n",
    "\n",
    "    train = {i:[] for i in train_classes}\n",
    "    valid = {i:[] for i in valid_classes}\n",
    "    test = {i:[] for i in test_classes}\n",
    "\n",
    "    for data, class_ in zip(x, y):\n",
    "        if class_ in train_classes:\n",
    "            train[class_].append(data)\n",
    "        \n",
    "        elif class_ in valid_classes:\n",
    "            valid[class_].append(data)\n",
    "\n",
    "        else:\n",
    "            test[class_].append(data)\n",
    "\n",
    "    for class_ in train_classes:\n",
    "        train[class_] = np.stack(train[class_])\n",
    "\n",
    "    for class_ in valid_classes:\n",
    "        valid[class_] = np.stack(valid[class_])\n",
    "\n",
    "    for class_ in test_classes:\n",
    "        test[class_] = np.stack(test[class_])\n",
    "\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 7\n",
    "\n",
    "(x, y), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "x = np.stack([cv2.resize(img/255.0, dsize=[SIZE, SIZE]) for img in x]).reshape(-1, SIZE**2)\n",
    "\n",
    "_, mnist_valid, mnist_test = split_dataset(x, y, valid_split=.5, test_split=.5)\n",
    "\n",
    "(x, y), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x = np.stack([cv2.resize(img/255.0, dsize=[SIZE, SIZE]) for img in x]).reshape(-1, SIZE**2)\n",
    "\n",
    "_, fashion_valid, fashion_test = split_dataset(x, y, valid_split=.5, test_split=.5)\n",
    "\n",
    "emnist = pd.read_csv(\"emnist-letters-train.csv\").values\n",
    "x, y = emnist[:, 1:], emnist[:, 0]\n",
    "x = np.stack([cv2.resize(cv2.flip(cv2.rotate(img.reshape(28, 28)/255.0, cv2.ROTATE_90_CLOCKWISE), 1), dsize=[SIZE, SIZE]) for img in x]).reshape(-1, SIZE**2)\n",
    "\n",
    "emnist_train, emnist_valid, emnist_test = split_dataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [emnist_train]\n",
    "valid = [mnist_valid, fashion_valid, emnist_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 128\n",
    "# TIME = 1\n",
    "# DT = .25\n",
    "\n",
    "# n_classes = 2\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# shape = [SIZE**2, 8, n_classes]\n",
    "# n_nodes = sum(shape)\n",
    "# connections = [(sum(shape[:i])+x, sum(shape[:i+1])+y) for i in range(len(shape)-1) for x in range(shape[i]) for y in range(shape[i+1])]\n",
    "\n",
    "# print(len(connections))\n",
    "\n",
    "# graph = NeuralGraph(n_nodes, SIZE**2, n_classes, connections,\n",
    "#     ch_n=4, ch_e=4, value_init=\"random\", init_value_std=.05, \n",
    "#     aggregation=\"mean\", use_label=True, clamp_mode=\"soft\", max_value=1e5, \n",
    "#     device=device)\n",
    "\n",
    "# log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.inp_int = ES.ES_MLP(nn.Sequential(ES.ES_Linear(5, 4))).to(device)\n",
    "# graph.label_int = ES.ES_MLP(nn.Sequential(ES.ES_Linear(5, 4))).to(device)\n",
    "# graph.out_int = ES.ES_MLP(nn.Sequential(ES.ES_Linear(4, 1))).to(device)\n",
    "# graph.messages = nn.ModuleList([ES.ES_MLP(nn.Sequential(\n",
    "#     ES.ES_Linear(12, 16),\n",
    "#     nn.ReLU(),\n",
    "#     ES.ES_Linear(16, 12)\n",
    "# ))]).to(device)\n",
    "# graph.updates = nn.ModuleList([ES.ES_MLP(nn.Sequential(\n",
    "#     ES.ES_Linear(12, 32),\n",
    "#     nn.ReLU(),\n",
    "#     ES.ES_Linear(32, 4)\n",
    "# ))]).to(device)\n",
    "\n",
    "# ruleset = [\n",
    "#     graph.inp_int,\n",
    "#     graph.label_int,\n",
    "#     graph.out_int,\n",
    "#     graph.messages[0],\n",
    "#     graph.updates[0],\n",
    "# ]\n",
    "# # for model in ruleset:\n",
    "# #     model.generate_epsilons(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ES.ES_NeuralGraph' from 'c:\\\\Users\\\\Alec\\\\Documents\\\\GitHub\\\\NeuralGraphPaper\\\\ES\\\\ES_NeuralGraph.py'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ES.ES_NeuralGraph\n",
    "importlib.reload(ES.ES_NeuralGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "TIME = 1\n",
    "DT = .25\n",
    "\n",
    "n_classes = 2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "shape = [SIZE**2, 8, n_classes]\n",
    "n_nodes = sum(shape)\n",
    "connections = torch.Tensor([[sum(shape[:i])+x, sum(shape[:i+1])+y] for i in range(len(shape)-1) for x in range(shape[i]) for y in range(shape[i+1])])\n",
    "\n",
    "print(len(connections))\n",
    "\n",
    "graph = ES.ES_NeuralGraph.NeuralGraph(n_nodes, SIZE**2, n_classes, connections,\n",
    "    ch_n=4, ch_e=4, init_mode=\"random\", init_std=.05, \n",
    "    aggregation=\"mean\", use_label=True, clamp_mode=\"soft\", max_value=1e5).to(device)\n",
    "\n",
    "log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EXAMPLES = 10\n",
    "TEST_EXAMPLES = 5\n",
    "# Reset optimizer\n",
    "# optimizer = torch.optim.Adam(graph.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.SGD(graph.parameters(), lr=1e-2)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "STEPS = 10_000\n",
    "\n",
    "log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_along_axis(a, axis):\n",
    "    idx = np.random.rand(*a.shape).argsort(axis=axis)\n",
    "    return np.take_along_axis(a,idx,axis=axis)\n",
    "\n",
    "def get_batch_data(dataset=train, batch_size=BATCH_SIZE, train_examples=TRAIN_EXAMPLES, test_examples=TEST_EXAMPLES):\n",
    "    if type(dataset) != list:\n",
    "        dataset = [dataset]\n",
    "    set_ = np.random.randint(len(dataset), size=(batch_size))\n",
    "\n",
    "    classes = np.stack([np.random.choice(list(dataset[i].keys()), size=(n_classes), replace=False) for i in set_])\n",
    "    \n",
    "    # This gets completely random examples\n",
    "    # y_train = np.random.randint(n_classes, size=(batch_size, train_examples))\n",
    "    # y_test = np.random.randint(n_classes, size=(batch_size, TEST_EXAMPLES))\n",
    "\n",
    "    # This gets balanced random examples\n",
    "    \n",
    "    y_train = np.repeat(np.expand_dims(np.round(np.linspace(0, n_classes-1, train_examples)), axis=0), batch_size, axis=0).astype(np.int32)\n",
    "    y_test = np.repeat(np.expand_dims(np.round(np.linspace(0, n_classes-1, test_examples)), axis=0), batch_size, axis=0).astype(np.int32)\n",
    "\n",
    "    y_train = shuffle_along_axis(y_train, axis=1)\n",
    "    y_test = shuffle_along_axis(y_test, axis=1)\n",
    "\n",
    "\n",
    "    x_train = []\n",
    "    for batch_classes, y, i in zip(classes, y_train, set_):\n",
    "        x_train.append([])\n",
    "        for class_ in batch_classes[y]:\n",
    "            x_train[-1].append(random.choice(dataset[i][class_]))\n",
    "        x_train[-1] = np.stack(x_train[-1])\n",
    "    x_train = np.stack(x_train)\n",
    "\n",
    "    x_test = []\n",
    "    for batch_classes, y, i in zip(classes, y_test, set_):\n",
    "        x_test.append([])\n",
    "        for class_ in batch_classes[y]:\n",
    "            x_test[-1].append(random.choice(dataset[i][class_]))\n",
    "        x_test[-1] = np.stack(x_test[-1])\n",
    "    x_test = np.stack(x_test)\n",
    "    \n",
    "    return torch.Tensor(x_train).to(device), torch.Tensor(y_train).long().to(device), torch.Tensor(x_test).to(device), torch.Tensor(y_test).long().to(device), classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e7554da8654f939edabd6d09df1d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alec\\Documents\\GitHub\\NeuralGraphPaper\\ES_NeuralGraph.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alec/Documents/GitHub/NeuralGraphPaper/ES_NeuralGraph.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m graph\u001b[39m.\u001b[39minit_vals(nodes\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, edges\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_size\u001b[39m=\u001b[39mBATCH_SIZE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alec/Documents/GitHub/NeuralGraphPaper/ES_NeuralGraph.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m graph\u001b[39m.\u001b[39mlearn(x_train, y_input, time\u001b[39m=\u001b[39mTIME, dt\u001b[39m=\u001b[39mDT, apply_once\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reset_nodes\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, edges\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, edges_at_end\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alec/Documents/GitHub/NeuralGraphPaper/ES_NeuralGraph.ipynb#X12sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m pred \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39;49mpredict(x_test, time\u001b[39m=\u001b[39;49mTIME, dt\u001b[39m=\u001b[39;49mDT, apply_once\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, reset_nodes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, edges\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alec/Documents/GitHub/NeuralGraphPaper/ES_NeuralGraph.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m valid_acc \u001b[39m=\u001b[39m (pred\u001b[39m.\u001b[39margmax(\u001b[39m2\u001b[39m) \u001b[39m==\u001b[39m y_test)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alec/Documents/GitHub/NeuralGraphPaper/ES_NeuralGraph.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m valid_loss \u001b[39m=\u001b[39m criterion(pred, y_label)\n",
      "File \u001b[1;32mc:\\Users\\Alec\\Documents\\GitHub\\NeuralGraphPaper\\ES\\ES_NeuralGraph.py:393\u001b[0m, in \u001b[0;36mNeuralGraph.predict\u001b[1;34m(self, X, time, dt, reset_nodes, **kwargs)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[39mif\u001b[39;00m reset_nodes:\n\u001b[0;32m    391\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_vals(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], nodes\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, edges\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 393\u001b[0m     preds\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(X[:, i], dt\u001b[39m=\u001b[39;49mdt, time\u001b[39m=\u001b[39;49mtime, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[0;32m    394\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(preds, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alec\\Documents\\GitHub\\NeuralGraphPaper\\ES\\ES_NeuralGraph.py:347\u001b[0m, in \u001b[0;36mNeuralGraph.forward\u001b[1;34m(self, x, time, dt, apply_once, nodes, edges, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m apply_once:\n\u001b[0;32m    346\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_vals(x)\n\u001b[1;32m--> 347\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimestep(step_nodes\u001b[39m=\u001b[39;49mnodes, step_edges\u001b[39m=\u001b[39;49medges, dt\u001b[39m=\u001b[39;49mdt, t\u001b[39m=\u001b[39;49mt)\n\u001b[0;32m    348\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_outputs()\n",
      "File \u001b[1;32mc:\\Users\\Alec\\Documents\\GitHub\\NeuralGraphPaper\\ES\\ES_NeuralGraph.py:172\u001b[0m, in \u001b[0;36mNeuralGraph.timestep\u001b[1;34m(self, dt, step_nodes, step_edges, t)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39m# nodes = self.nodes.clone() if (self.pool is None) else self.nodes[self.pool]\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39m# edges = self.edges.clone() if (self.pool is None) else self.edges[self.pool]\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[39m# Get messages\u001b[39;00m\n\u001b[0;32m    171\u001b[0m m_x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnodes[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msources], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnodes[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medges], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessages[t \u001b[39m%\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_models](m_x)\n\u001b[0;32m    174\u001b[0m m_a, m_b, m_ab \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor_split(m, [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mch_n\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mch_n_const, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mch_n\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mch_n_const)\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m], \u001b[39m2\u001b[39m)\n\u001b[0;32m    176\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregation \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mattention\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Alec\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Alec\\Documents\\GitHub\\NeuralGraphPaper\\ES\\ES_classes.py:86\u001b[0m, in \u001b[0;36mES_MLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     84\u001b[0m     \u001b[39m# Whatever we do its without explicit grad calcs\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 86\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msequential(x)\n",
      "File \u001b[1;32mc:\\Users\\Alec\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Alec\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Alec\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    bar = tqdm(range(1, STEPS+1))\n",
    "    for step in bar:\n",
    "\n",
    "        # Train step\n",
    "        x_train, y_train, x_test, y_test, classes = get_batch_data(dataset=train)\n",
    "        y_input = nn.functional.one_hot(y_train, n_classes).float()\n",
    "        y_label = nn.functional.one_hot(y_test, n_classes).float()\n",
    "\n",
    "        graph.generate_epsilons(BATCH_SIZE)\n",
    "        graph.init_vals(nodes=True, edges=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "        graph.learn(x_train, y_input, time=TIME, dt=DT, apply_once=True, reset_nodes=True, edges=False, edges_at_end=True)\n",
    "        pred = graph.predict(x_test, time=TIME, dt=DT, apply_once=True, reset_nodes=True, edges=False)\n",
    "\n",
    "        acc = (pred.argmax(2) == y_test).float().mean()\n",
    "\n",
    "        task_losses = torch.square(pred - y_label).mean(-1).mean(-1)\n",
    "        graph.estimate_grads(task_losses)\n",
    "        \n",
    "        # print(task_losses)\n",
    "        # assert False\n",
    "\n",
    "        task_loss = task_losses.mean()\n",
    "        overflow = graph.overflow()\n",
    "        \n",
    "        loss = task_loss + overflow\n",
    "        optimizer.step()\n",
    "\n",
    "        # Valid step (currently just validating with perturbations but could change to do not train_mode)\n",
    "        x_train, y_train, x_test, y_test, classes = get_batch_data(dataset=valid)\n",
    "        y_input = nn.functional.one_hot(y_train, n_classes).float()\n",
    "        y_label = nn.functional.one_hot(y_test, n_classes).float()\n",
    "\n",
    "        graph.init_vals(nodes=True, edges=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "        graph.learn(x_train, y_input, time=TIME, dt=DT, apply_once=True, reset_nodes=True, edges=False, edges_at_end=True)\n",
    "        pred = graph.predict(x_test, time=TIME, dt=DT, apply_once=True, reset_nodes=True, edges=False)\n",
    "\n",
    "        valid_acc = (pred.argmax(2) == y_test).float().mean()\n",
    "        valid_loss = criterion(pred, y_label)\n",
    "\n",
    "\n",
    "        # Save\n",
    "        # if step % 500 == 0 and step != 0:\n",
    "        #     graph.save(f\"models/generalize_{step}.pt\")\n",
    "\n",
    "        entry = {'valid_loss':valid_loss.item(), 'valid_acc':valid_acc.item(), 'loss': task_loss.item(), 'acc': acc.item(), \"overflow\": overflow.item()}\n",
    "        log.append(entry)\n",
    "        bar.set_postfix({\"valid_loss\":np.mean([e[\"valid_loss\"] for e in log[-10:]]), \"valid_acc\":np.mean([e[\"valid_acc\"] for e in log[-10:]]), \"loss\":np.mean([e[\"loss\"] for e in log[-10:]]), \"acc\":np.mean([e[\"acc\"] for e in log[-10:]]), \"overflow\":entry[\"overflow\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26904ceac10>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([e[\"loss\"] for e in log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: tensor([4.2000, 1.8000, 7.5000, 2.3000, 5.1000])\n",
      "Rank-normalized Tensor: tensor([0.4000, 0.8000, 0.0000, 0.6000, 0.2000])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
