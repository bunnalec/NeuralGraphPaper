{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ES.ES_classes as ES\n",
    "import importlib\n",
    "importlib.reload(ES)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from NeuralGraph import NeuralGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d4a2cf72d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x, y, valid_split=.2, test_split=.2):\n",
    "    classes = np.unique(y)\n",
    "    train_valid_split = round(len(classes)*(1-(valid_split+test_split)))\n",
    "    valid_test_split = round(len(classes)*(1-test_split))\n",
    "\n",
    "    train_classes = set(classes[:train_valid_split])\n",
    "    valid_classes = set(classes[train_valid_split:valid_test_split])\n",
    "    test_classes = set(classes[valid_test_split:])\n",
    "\n",
    "    train = {i:[] for i in train_classes}\n",
    "    valid = {i:[] for i in valid_classes}\n",
    "    test = {i:[] for i in test_classes}\n",
    "\n",
    "    for data, class_ in zip(x, y):\n",
    "        if class_ in train_classes:\n",
    "            train[class_].append(data)\n",
    "        \n",
    "        elif class_ in valid_classes:\n",
    "            valid[class_].append(data)\n",
    "\n",
    "        else:\n",
    "            test[class_].append(data)\n",
    "\n",
    "    for class_ in train_classes:\n",
    "        train[class_] = np.stack(train[class_])\n",
    "\n",
    "    for class_ in valid_classes:\n",
    "        valid[class_] = np.stack(valid[class_])\n",
    "\n",
    "    for class_ in test_classes:\n",
    "        test[class_] = np.stack(test[class_])\n",
    "\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 7\n",
    "\n",
    "# (x, y), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "# x = np.stack([cv2.resize(img/255.0, dsize=[SIZE, SIZE]) for img in x]).reshape(-1, SIZE**2)\n",
    "\n",
    "# _, mnist_valid, mnist_test = split_dataset(x, y, valid_split=.5, test_split=.5)\n",
    "\n",
    "# (x, y), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# x = np.stack([cv2.resize(img/255.0, dsize=[SIZE, SIZE]) for img in x]).reshape(-1, SIZE**2)\n",
    "\n",
    "# _, fashion_valid, fashion_test = split_dataset(x, y, valid_split=.5, test_split=.5)\n",
    "\n",
    "# emnist = pd.read_csv(\"emnist-letters-train.csv\").values\n",
    "# x, y = emnist[:, 1:], emnist[:, 0]\n",
    "# x = np.stack([cv2.resize(cv2.flip(cv2.rotate(img.reshape(28, 28)/255.0, cv2.ROTATE_90_CLOCKWISE), 1), dsize=[SIZE, SIZE]) for img in x]).reshape(-1, SIZE**2)\n",
    "\n",
    "# emnist_train, emnist_valid, emnist_test = split_dataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = [emnist_train]\n",
    "# valid = [mnist_valid, fashion_valid, emnist_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 512\n",
    "TIME = 1\n",
    "DT = .25\n",
    "\n",
    "n_classes = 2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "shape = [SIZE**2, n_classes]\n",
    "n_nodes = sum(shape)\n",
    "connections = [(sum(shape[:i])+x, sum(shape[:i+1])+y) for i in range(len(shape)-1) for x in range(shape[i]) for y in range(shape[i+1])]\n",
    "\n",
    "print(len(connections))\n",
    "\n",
    "graph = NeuralGraph(n_nodes, SIZE**2, n_classes, connections,\n",
    "    ch_n=8, ch_e=8, value_init=\"random\", init_value_std=.05, \n",
    "    aggregation=\"mean\", use_label=True, clamp_mode=\"soft\", max_value=1e5, \n",
    "    device=device)\n",
    "\n",
    "log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.inp_int = ES.ES_MLP(nn.Sequential(ES.ES_Linear(9, 8))).to(device)\n",
    "graph.label_int = ES.ES_MLP(nn.Sequential(ES.ES_Linear(9, 8))).to(device)\n",
    "graph.out_int = ES.ES_MLP(nn.Sequential(ES.ES_Linear(8, 1))).to(device)\n",
    "graph.messages = nn.ModuleList([ES.ES_MLP(nn.Sequential(\n",
    "    ES.ES_Linear(24, 32),\n",
    "    nn.Tanh(),\n",
    "    ES.ES_Linear(32, 24)\n",
    "))]).to(device)\n",
    "graph.updates = nn.ModuleList([ES.ES_MLP(nn.Sequential(\n",
    "    ES.ES_Linear(24, 32),\n",
    "    nn.Tanh(),\n",
    "    ES.ES_Linear(32, 8)\n",
    "))]).to(device)\n",
    "\n",
    "ruleset = [\n",
    "    graph.inp_int,\n",
    "    graph.label_int,\n",
    "    graph.out_int,\n",
    "    graph.messages[0],\n",
    "    graph.updates[0],\n",
    "]\n",
    "for model in ruleset:\n",
    "    model.generate_epsilons(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.init_vals(batch_size=BATCH_SIZE)\n",
    "graph.timestep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
